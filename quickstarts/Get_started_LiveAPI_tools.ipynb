{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini 2.0 - Multimodal live API: Tool use\n",
    "This notebook provides examples of how to use tools with the multimodal live API with [Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2).\n",
    "\n",
    "The API provides Google Search, Code Execution and Function Calling tools. The earlier Gemini models supported versions of these tools. The biggest change with Gemini 2 (in the Live API) is that, basically, all the tools are handled by Code Execution. With that change, you can use **multiple tools** in a single API call, and the model can use multiple tools in a single code execution block.  \n",
    "\n",
    "This tutorial assumes you are familiar with the Live API, as described in the [this tutorial](../quickstarts/Get_started_LiveAPI.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install the Google GenAI SDK\n",
    "\n",
    "Install the Google GenAI SDK from [npm](https://www.npmjs.com/package/@google/genai). \n",
    "\n",
    "```bash\n",
    "$ npm install @google/genai\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup your API key\n",
    "\n",
    "You can [create](https://aistudio.google.com/app/apikey) your API key using Google AI Studio with a single click.\n",
    "\n",
    "Remember to treat your API key like a password. Don't accidentally save it in a notebook or source file you later commit to GitHub. In this notebook we will be storing the API key in a `.env` file. You can also set it as an environment variable or use a secret manager. \n",
    "\n",
    "Here's how to set it up in a `.env` file:\n",
    "\n",
    "```bash\n",
    "$ touch .env\n",
    "$ echo \"GEMINI_API_KEY=<YOUR_API_KEY>\" >> .env\n",
    "```\n",
    "\n",
    ":::{.callout-tip}\n",
    "\n",
    "Another option is to set the API key as an environment variable. You can do this in your terminal with the following command:\n",
    "\n",
    "```bash\n",
    "$ export GEMINI_API_KEY=\"<YOUR_API_KEY>\"\n",
    "```\n",
    ":::\n",
    "\n",
    "### Load the API key\n",
    "\n",
    "To load the API key from the `.env` file, we will use the `dotenv` package. This package loads environment variables from a `.env` file into `process.env`. \n",
    "\n",
    "```bash\n",
    "$ npm install dotenv\n",
    "```\n",
    "\n",
    "Then, we can load the API key in our code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY is set in the environment variables\n"
     ]
    }
   ],
   "source": [
    "const dotenv = require(\"dotenv\") as typeof import(\"dotenv\");\n",
    "\n",
    "dotenv.config({\n",
    "  path: \"../.env\",\n",
    "});\n",
    "\n",
    "const GEMINI_API_KEY = process.env.GEMINI_API_KEY ?? \"\";\n",
    "if (!GEMINI_API_KEY) {\n",
    "  throw new Error(\"GEMINI_API_KEY is not set in the environment variables\");\n",
    "}\n",
    "console.log(\"GEMINI_API_KEY is set in the environment variables\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "In our particular case the `.env` is is one directory up from the notebook, hence we need to use `../` to go up one directory. If the `.env` file is in the same directory as the notebook, you can omit it altogether. \n",
    "\n",
    "```\n",
    "│\n",
    "├── .env\n",
    "└── quickstarts\n",
    "    └── Get_started_LiveAPI_tools.ipynb\n",
    "```\n",
    ":::\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize SDK Client\n",
    "\n",
    "With the new SDK, now you only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "const google = require(\"@google/genai\") as typeof import(\"@google/genai\");\n",
    "\n",
    "const ai = new google.GoogleGenAI({ apiKey: GEMINI_API_KEY });\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model\n",
    "\n",
    "Multimodal Live API are a new capability introduced with the [Gemini 2.0](https://ai.google.dev/gemini-api/docs/models/gemini-v2) model. It won't work with previous generation models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "const tslab = require(\"tslab\") as typeof import(\"tslab\");\n",
    "\n",
    "const MODEL_ID = \"gemini-2.0-flash-live-001\";\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilites\n",
    "\n",
    "You're going to use the Live API's audio output, the easiest way hear it in Colab is to write the PCM data out as a WAV file:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "const fs = require(\"fs\") as typeof import(\"fs\");\n",
    "const path = require(\"path\") as typeof import(\"path\");\n",
    "const wave = require(\"wavefile\") as typeof import(\"wavefile\");\n",
    "\n",
    "function saveAudioToFile(audioData: Int16Array, filePath: string) {\n",
    "  fs.mkdirSync(path.dirname(filePath), { recursive: true });\n",
    "  const wav = new wave.WaveFile();\n",
    "  wav.fromScratch(1, 24000, \"16\", audioData);\n",
    "  fs.writeFileSync(filePath, wav.toBuffer());\n",
    "  console.debug(`Audio saved to ${filePath}`);\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "\n",
    "Most of the Live API setup will be similar to the [starter tutorial](quickstarts/Get_started_LiveAPI.ipynb). Since this tutorial doesn't focus on the realtime interactivity of the API, the code has been simplified: This code uses the Live API, but it only sends a single text prompt, and listens for a single turn of replies.\n",
    "\n",
    "You can set modality=\"AUDIO\" on any of the examples to get the spoken version of the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [

    "import { FunctionResponse, LiveServerContent, LiveServerToolCall, Modality, Session, Tool } from \"@google/genai\";\n",
    "\n",
    "function handleServerContent(content: LiveServerContent) {\n",
    "  if (content.modelTurn) {\n",
    "    for (const turn of content.modelTurn.parts ?? []) {\n",
    "      if (turn.executableCode) {\n",
    "        tslab.display.markdown(\"-------------------------------\");\n",
    "        tslab.display.markdown(`\\`\\`\\`python\\n${turn.executableCode.code}\\n\\`\\`\\``);\n",
    "        tslab.display.markdown(\"-------------------------------\");\n",
    "      }\n",
    "      if (turn.codeExecutionResult) {\n",
    "        tslab.display.markdown(\"-------------------------------\");\n",
    "        tslab.display.markdown(`\\`\\`\\`\\n${turn.codeExecutionResult.output}\\n\\`\\`\\``);\n",
    "        tslab.display.markdown(\"-------------------------------\");\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  if (content.groundingMetadata) {\n",
    "    tslab.display.html(content.groundingMetadata.searchEntryPoint?.renderedContent ?? \"\");\n",
    "  }\n",
    "}\n",
    "\n",
    "function handleToolCall(session: Session, toolCall: LiveServerToolCall) {\n",
    "  const responses: FunctionResponse[] = [];\n",
    "  for (const fc of toolCall.functionCalls ?? []) {\n",
    "    responses.push({\n",
    "      id: fc.id,\n",
    "      name: fc.name,\n",
    "      response: {\n",
    "        result: \"ok\",\n",
    "      },\n",
    "    });\n",
    "  }\n",
    "  console.log(\"Tool call responses:\", JSON.stringify(responses, null, 2));\n",
    "  session.sendToolResponse({\n",
    "    functionResponses: responses,\n",
    "  });\n",
    "}\n",
    "\n",
    "async function run(prompt: string, modality: Modality = Modality.TEXT, tools: Tool[] = []) {\n",
    "  const audioData: number[] = [];\n",
    "  const audioFileName = `audio-${Date.now()}.wav`;\n",
    "  let completed = false;\n",
    "  const session = await ai.live.connect({\n",
    "    model: MODEL_ID,\n",
    "    callbacks: {\n",
    "      onopen: () => {\n",
    "        console.log(\"Connection opened\");\n",
    "      },\n",
    "      onclose: () => {\n",
    "        console.log(\"Connection closed\");\n",
    "      },\n",
    "      onerror: (error) => {\n",
    "        console.error(\"Error:\", error.message);\n",
    "      },\n",
    "      onmessage: (message) => {\n",
    "        if (message.text) {\n",
    "          tslab.display.markdown(message.text);\n",
    "          return;\n",
    "        }\n",
    "        if (message.data) {\n",
    "          const audioBuffer = Buffer.from(message.data, \"base64\");\n",
    "          const audio = new Int16Array(\n",
    "            audioBuffer.buffer,\n",
    "            audioBuffer.byteOffset,\n",
    "            audioBuffer.length / Int16Array.BYTES_PER_ELEMENT\n",
    "          );\n",
    "          audioData.push(...audio);\n",
    "          return;\n",
    "        }\n",
    "        if (message.serverContent) {\n",
    "          handleServerContent(message.serverContent);\n",
    "          if (message.serverContent.turnComplete) {\n",
    "            completed = true;\n",
    "          }\n",
    "          return;\n",
    "        }\n",
    "        if (message.toolCall) {\n",
    "          handleToolCall(session, message.toolCall);\n",
    "          completed = true;\n",
    "          return;\n",
    "        }\n",
    "      },\n",
    "    },\n",
    "    config: {\n",
    "      tools: tools,\n",
    "      responseModalities: [modality],\n",
    "    },\n",
    "  });\n",
    "  console.log(\"Prompt: \", prompt);\n",
    "  session.sendClientContent({\n",
    "    turns: [prompt],\n",
    "    turnComplete: true,\n",
    "  });\n",
    "  // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition\n",
    "  while (!completed) {\n",
    "    await new Promise((resolve) => setTimeout(resolve, 100));\n",
    "  }\n",
    "  if (audioData.length > 0) {\n",
    "    saveAudioToFile(new Int16Array(audioData), path.join(\"audio\", audioFileName));\n",
    "    console.log(`Audio saved to ${audioFileName}`);\n",
    "    tslab.display.html(\n",
    "      `<audio controls><source src=\"${audioFileName}\" type=\"audio/wav\">Your browser does not support the audio element.</audio>`\n",
    "    );\n",
    "  }\n",
    "  console.log(\"Session completed\");\n",
    "  session.close();\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this tutorial demonstrates several tools, you'll need more code to handle the different types of objects it returns.\n",
    "\n",
    "- The `codeExecution` tool can return `executableCode` and `codeExecutionResult` parts.\n",
    "- The `googleSearch` tool may attach a `groundingMetadata` object.\n",
    "- Finally, with the `functionDeclations` tool, the API may return `toolCall` objects.To keep this code minimal, the `toolCall` handler just replies to every function call with a response of `\"ok\"`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened\n",
      "Prompt:  Hello?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Hello! How can"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " I help you today?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "await run(\"Hello?\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Function Call\n",
    "\n",
    "The function calling feature of the API Can handle a wide variety of functions. Support in the SDK is still under construction. So keep this simple just send a minimal function definition: Just the function's name.\n",
    "\n",
    "Note that in the live API function calls are independent of the chat turns. The conversation can continue while a function call is being processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened\n",
      "Prompt:  Turn on the lights\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "print(default_api.turn_on_the_lights())\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call responses: [\n",
      "  {\n",
      "    \"id\": \"function-call-16720258795371319743\",\n",
      "    \"name\": \"turn_on_the_lights\",\n",
      "    \"response\": {\n",
      "      \"result\": \"ok\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "{'result': 'ok'}\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "OK"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ", I've turned on the lights.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed\n"
     ]
    }
   ],
   "source": [

    "import { FunctionDeclaration, Tool } from \"@google/genai\";\n",
    "\n",
    "const turn_on_the_lights = {\n",
    "  name: \"turn_on_the_lights\",\n",
    "  description: \"Turn on the lights in the room\",\n",
    "} satisfies FunctionDeclaration;\n",
    "const turn_off_the_lights: FunctionDeclaration = {\n",
    "  name: \"turn_off_the_lights\",\n",
    "  description: \"Turn off the lights in the room\",\n",
    "} satisfies FunctionDeclaration;\n",
    "const function_call_tools: Tool[] = [{ functionDeclarations: [turn_on_the_lights, turn_off_the_lights] }];\n",
    "\n",
    "// temporarily make console.warn a no-op to avoid warnings in the output (non-text part in GenerateContentResponse caused by accessing .text)\n",
    "// https://github.com/googleapis/js-genai/blob/d82aba244bdb804b063ef8a983b2916c00b901d2/src/types.ts#L2005\n",
    "// copy the original console.warn function to restore it later\n",
    "const warn_fn = console.warn;\n",
    "// eslint-disable-next-line @typescript-eslint/no-empty-function, no-empty-function\n",
    "console.warn = function () {};\n",
    "\n",
    "await run(\"Turn on the lights\", google.Modality.TEXT, function_call_tools);\n",
    "// restore console.warn later\n",
    "// console.warn = warn_fn;\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Execution\n",
    "\n",
    "The `codeExecution lets` the model write and run python code. Try it on a math problem the model can't solve from memory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened\n",
      "Prompt:  Can you compute the largest prime palindrome under 100000.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Okay"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ", I can help you with that. Here's my plan:\n",
       "\n",
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ".  **Generate Palindromes:** Create a list of all palindromes under 100000.\n",
       "2.  **Check for Primality:**"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " Iterate through the palindromes and check if each one is prime.\n",
       "3.  **Find the Largest:** Keep track of the largest prime palindrome found so far.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here's the code to do that:\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def is_palindrome(n):\n",
       "  \"\"\"Checks if a number is a palindrome.\"\"\"\n",
       "  return str(n) == str(n)[::-1]\n",
       "\n",
       "\n",
       "def is_prime(n):\n",
       "  \"\"\"Checks if a number is prime.\"\"\"\n",
       "  if n < 2:\n",
       "    return False\n",
       "  for i in range(2, int(n**0.5) + 1):\n",
       "    if n % i == 0:\n",
       "      return False\n",
       "  return True\n",
       "\n",
       "\n",
       "largest_prime_palindrome = 0\n",
       "for i in range(100000):\n",
       "  if is_palindrome(i) and is_prime(i):\n",
       "    largest_prime_palindrome = i\n",
       "\n",
       "print(largest_prime_palindrome)\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "98689\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The largest prime palindrome"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " under 100000 is 98689."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "await run(\"Can you compute the largest prime palindrome under 100000.\", google.Modality.TEXT, [{ codeExecution: {} }]);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compositional Function Calling\n",
    "\n",
    "Compositional function calling refers to the ability to combine user defined functions with the `codeExecution` tool. The model will write them into larger blocks of code, and then pause execution while it waits for you to send back responses for each call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened\n",
      "Prompt:  Can you turn on the lights wait 10s and then turn them off?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import time\n",
       "\n",
       "default_api.turn_on_the_lights()\n",
       "time.sleep(10)\n",
       "default_api.turn_off_the_lights()\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call responses: [\n",
      "  {\n",
      "    \"id\": \"function-call-448821244251533960\",\n",
      "    \"name\": \"turn_on_the_lights\",\n",
      "    \"response\": {\n",
      "      \"result\": \"ok\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "Session completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "await run(\"Can you turn on the lights wait 10s and then turn them off?\", google.Modality.TEXT, [\n",
    "  ...function_call_tools,\n",
    "  { codeExecution: {} },\n",
    "]);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google search\n",
    "\n",
    "The `googleSearch` tool lets the model conduct google searches. For example, try asking it about events that are too recent to be in the training data.\n",
    "\n",
    "The search will still execute in `AUDIO` mode, but you won't see the detailed results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened\n",
      "Prompt:  When the latest Brazil vs. Argentina soccer match happened and what was the final score?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "print(google_search.search(queries=[\"latest Brazil vs Argentina soccer match date and score\", \"Brazil vs Argentina recent match results\"]))\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Looking up information on Google Search.\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The most recent match"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " between Brazil and Argentina took place on **March 25, 20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "25**, as part of the 2026 FIFA World Cup qualifiers. Argentina won the match with a final score of **4-1**.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXFadx8wh7X7fK0aBupnT_eAVjMgT_lLIouI3EEzxzsN3Q35oUZQOI1PPKKRUU_cjbTsQa5zCO4cxUtBfDc4GX216IeGJ6MZEWtLDnZW_IOwsJeKlJCpehrvc9uqnOLYvB63nGzQQRmbJiLyF77s6DY-ONPDm3_YLXH5V6y-RycToxFCTl-hNVd7myrCYU0QFsQuA8uw_bIs9Uiro2SED9cTuZnaa-b6\">Brazil vs Argentina recent match results</a>\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEu7kT0Y6vz3h-O7f526GIQc-tckBiJo9F9_ribvj8w5SWV78j8uBEvA1Eyyz_xOVZG6dqqEiq1JKYXEmi6dT-srC4ZBVH5i0rON5cWLK4W-uCxK-ak19XW2vUF04VqF0e5yQ-B0JliMEhD03uawD2xOlO1xo6GEK5MlwFfMXc0pDi2MMLB-MFkvvhjwF_b8CYjz1g5lxJPdIZBs2MSNVd1gOCdz6OxkXWS23MTt1J-l11Z4SoR\">latest Brazil vs Argentina soccer match date and score</a>\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "await run(\n",
    "  \"When the latest Brazil vs. Argentina soccer match happened and what was the final score?\",\n",
    "  google.Modality.TEXT,\n",
    "  [{ googleSearch: {} }]\n",
    ");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple tools\n",
    "\n",
    "The biggest difference with the new API however is that you're no longer limited to using 1-tool per request. Try combining those tasks from the previous sections:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection opened\n",
      "Prompt:  \n",
      "  Hey, I need you to do three things for me.\n",
      "\n",
      "  1. Then compute the largest prime plaindrome under 100000.\n",
      "  2. Then use google search to lookup unformation about the largest earthquake in california the week of Dec 5 2024?\n",
      "  3. Turn on the lights\n",
      "\n",
      "  Thanks!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Okay"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ", I can do that. Here's the plan:\n",
       "\n",
       "1.  Compute"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " the largest prime palindrome under 100000. I'll use a Python script to achieve this.\n",
       "2.  Use Google Search to look up"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " information about the largest earthquake in California the week of Dec 5 2024.\n",
       "3.  Turn on the lights using the provided API.\n",
       "\n",
       "Here"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "'s the first step, computing the largest prime palindrome under 100000:\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def is_palindrome(n):\n",
       "  return str(n) == str(n)[::-1]\n",
       "\n",
       "def is_prime(n):\n",
       "  if n < 2:\n",
       "    return False\n",
       "  for i in range(2, int(n**0.5) + 1):\n",
       "    if n % i == 0:\n",
       "      return False\n",
       "  return True\n",
       "\n",
       "largest_prime_palindrome = 0\n",
       "for i in range(99999, 1, -1):\n",
       "  if is_palindrome(i) and is_prime(i):\n",
       "    largest_prime_palindrome = i\n",
       "    break\n",
       "\n",
       "print(largest_prime_palindrome)\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "98689\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Okay"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ", the largest prime palindrome under 100000 is 98689."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "Now, let's use Google Search to find the largest earthquake in California the week of Dec 5 2024."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "concise_search(\"largest earthquake california week of December 5 2024\", max_num_results=5)\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "Looking up information on Google Search.\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Based"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " on the search results, the largest earthquake in California during the week of December "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5, 2024, was a magnitude 7.0 earthquake offshore of Cape Mendocino on December 5, 2024,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " at 10:44 a.m. PST.\n",
       "\n",
       "Finally, I will turn on the lights.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "default_api.turn_on_the_lights()\n",
       "\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGTCTeCs3fRPcOH0kyLP6xl7S6tPuIzCYcVNVGxPIkfW6W8Zd8I24-HazTND3A__0FnE02-f4otHQPJJII2L8vLX432Qki9jeJbgetPQ4rbbIyD2ZqUwNZNej0RZOZ_lFi0U_yh_ZQ-vi3dHelmu-qzMm6ykJHvdCNSOytVmPLyJtd2sicsWCwV0CHAzp3gyqEQLgq8Ysw5c9xzkhSRglI3Epdly083QVfyBk1cuB-OB5DOhw==\">largest earthquake california week of December 5 2024</a>\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call responses: [\n",
      "  {\n",
      "    \"id\": \"function-call-10200942088489058256\",\n",
      "    \"name\": \"turn_on_the_lights\",\n",
      "    \"response\": {\n",
      "      \"result\": \"ok\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "Session completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed\n"
     ]
    }
   ],
   "source": [

    "import { Tool } from \"@google/genai\";\n",
    "\n",
    "const multi_tool_prompt = `\n",
    "  Hey, I need you to do three things for me.\n",
    "\n",
    "  1. Then compute the largest prime plaindrome under 100000.\n",
    "  2. Then use google search to lookup unformation about the largest earthquake in california the week of Dec 5 2024?\n",
    "  3. Turn on the lights\n",
    "\n",
    "  Thanks!\n",
    "`;\n",
    "const multi_tool_tools: Tool[] = [\n",
    "  { codeExecution: {} },\n",
    "  { googleSearch: {} },\n",
    "  { functionDeclarations: [turn_on_the_lights, turn_off_the_lights] },\n",
    "];\n",
    "\n",
    "await run(multi_tool_prompt, google.Modality.TEXT, multi_tool_tools);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- For more information about the SDK see the [SDK docs](https://googleapis.github.io/js-genai/)\n",
    "- This tutorial uses the high level SDK, if you're interested in the lower-level details, try the [Websocket version of this tutorial](quickstarts/websockets/Get_started_LiveAPI_tools.ipynb)\n",
    "- This tutorial only covers _basic_ usage of these tools for deeper (and more fun) example see the [Search tool tutorial](quickstarts/Search_Grounding.ipynb)\n",
    "\n",
    "Or check the other Gemini 2.0 capabilities from the Cookbook, in particular this other [multi-tool](examples/LiveAPI_plotting_and_mapping.ipynb) example and the one about Gemini [spatial capabilities](quickstarts/Spatial_understanding.ipynb).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
