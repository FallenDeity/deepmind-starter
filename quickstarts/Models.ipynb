{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini API: List models\n",
    "\n",
    "This notebook demonstrates how to list the models that are available for you to use in the Gemini API, and how to find details about a model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install the Google GenAI SDK\n",
    "\n",
    "Install the Google GenAI SDK from [npm](https://www.npmjs.com/package/@google/genai). \n",
    "\n",
    "```bash\n",
    "$ npm install @google/genai\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup your API key\n",
    "\n",
    "You can [create](https://aistudio.google.com/app/apikey) your API key using Google AI Studio with a single click.\n",
    "\n",
    "Remember to treat your API key like a password. Don't accidentally save it in a notebook or source file you later commit to GitHub. In this notebook we will be storing the API key in a `.env` file. You can also set it as an environment variable or use a secret manager. \n",
    "\n",
    "Here's how to set it up in a `.env` file:\n",
    "\n",
    "```bash\n",
    "$ touch .env\n",
    "$ echo \"GEMINI_API_KEY=<YOUR_API_KEY>\" >> .env\n",
    "```\n",
    "\n",
    ":::{.callout-tip}\n",
    "\n",
    "Another option is to set the API key as an environment variable. You can do this in your terminal with the following command:\n",
    "\n",
    "```bash\n",
    "$ export GEMINI_API_KEY=\"<YOUR_API_KEY>\"\n",
    "```\n",
    ":::\n",
    "\n",
    "### Load the API key\n",
    "\n",
    "To load the API key from the `.env` file, we will use the `dotenv` package. This package loads environment variables from a `.env` file into `process.env`. \n",
    "\n",
    "```bash\n",
    "$ npm install dotenv\n",
    "```\n",
    "\n",
    "Then, we can load the API key in our code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY is set in the environment variables\n"
     ]
    }
   ],
   "source": [
    "const dotenv = require(\"dotenv\") as typeof import(\"dotenv\");\n",
    "\n",
    "dotenv.config({\n",
    "  path: \"../.env\",\n",
    "});\n",
    "\n",
    "const GEMINI_API_KEY = process.env.GEMINI_API_KEY ?? \"\";\n",
    "if (!GEMINI_API_KEY) {\n",
    "  throw new Error(\"GEMINI_API_KEY is not set in the environment variables\");\n",
    "}\n",
    "console.log(\"GEMINI_API_KEY is set in the environment variables\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "In our particular case the `.env` is is one directory up from the notebook, hence we need to use `../` to go up one directory. If the `.env` file is in the same directory as the notebook, you can omit it altogether. \n",
    "\n",
    "```\n",
    "\u2502\n",
    "\u251c\u2500\u2500 .env\n",
    "\u2514\u2500\u2500 quickstarts\n",
    "    \u2514\u2500\u2500 Models.ipynb\n",
    "```\n",
    ":::\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize SDK Client\n",
    "\n",
    "With the new SDK, now you only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "const google = require(\"@google/genai\") as typeof import(\"@google/genai\");\n",
    "\n",
    "const ai = new google.GoogleGenAI({ apiKey: GEMINI_API_KEY });\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List models\n",
    "\n",
    "Use `models.list()` to see what models are available. These models support `generateContent`, the main method used for prompting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- models/embedding-gecko-001 (Embedding Gecko) | [Actions: embedText, countTextTokens]\n",
      "- models/gemini-1.0-pro-vision-latest (Gemini 1.0 Pro Vision) | [Actions: generateContent, countTokens]\n",
      "- models/gemini-pro-vision (Gemini 1.0 Pro Vision) | [Actions: generateContent, countTokens]\n",
      "- models/gemini-1.5-pro-latest (Gemini 1.5 Pro Latest) | [Actions: generateContent, countTokens]\n",
      "- models/gemini-1.5-pro-002 (Gemini 1.5 Pro 002) | [Actions: generateContent, countTokens, createCachedContent]\n",
      "- models/gemini-1.5-pro (Gemini 1.5 Pro) | [Actions: generateContent, countTokens]\n",
      "- models/gemini-1.5-flash-latest (Gemini 1.5 Flash Latest) | [Actions: generateContent, countTokens]\n",
      "- models/gemini-1.5-flash (Gemini 1.5 Flash) | [Actions: generateContent, countTokens]\n",
      "- models/gemini-1.5-flash-002 (Gemini 1.5 Flash 002) | [Actions: generateContent, countTokens, createCachedContent]\n",
      "- models/gemini-1.5-flash-8b (Gemini 1.5 Flash-8B) | [Actions: createCachedContent, generateContent, countTokens]\n",
      "- models/gemini-1.5-flash-8b-001 (Gemini 1.5 Flash-8B 001) | [Actions: createCachedContent, generateContent, countTokens]\n",
      "- models/gemini-1.5-flash-8b-latest (Gemini 1.5 Flash-8B Latest) | [Actions: createCachedContent, generateContent, countTokens]\n",
      "- models/gemini-2.5-pro-exp-03-25 (Gemini 2.5 Pro Experimental 03-25) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.5-pro-preview-03-25 (Gemini 2.5 Pro Preview 03-25) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.5-flash-preview-04-17 (Gemini 2.5 Flash Preview 04-17) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.5-flash-preview-05-20 (Gemini 2.5 Flash Preview 05-20) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.5-flash-preview-04-17-thinking (Gemini 2.5 Flash Preview 04-17 for cursor testing) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.5-pro-preview-05-06 (Gemini 2.5 Pro Preview 05-06) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.5-pro-preview-06-05 (Gemini 2.5 Pro Preview) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-flash-exp (Gemini 2.0 Flash Experimental) | [Actions: generateContent, countTokens, bidiGenerateContent]\n",
      "- models/gemini-2.0-flash (Gemini 2.0 Flash) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-flash-001 (Gemini 2.0 Flash 001) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-flash-exp-image-generation (Gemini 2.0 Flash (Image Generation) Experimental) | [Actions: generateContent, countTokens, bidiGenerateContent]\n",
      "- models/gemini-2.0-flash-lite-001 (Gemini 2.0 Flash-Lite 001) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-flash-lite (Gemini 2.0 Flash-Lite) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-flash-preview-image-generation (Gemini 2.0 Flash Preview Image Generation) | [Actions: generateContent, countTokens]\n",
      "- models/gemini-2.0-flash-lite-preview-02-05 (Gemini 2.0 Flash-Lite Preview 02-05) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-flash-lite-preview (Gemini 2.0 Flash-Lite Preview) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-pro-exp (Gemini 2.0 Pro Experimental) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-pro-exp-02-05 (Gemini 2.0 Pro Experimental 02-05) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-exp-1206 (Gemini Experimental 1206) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-flash-thinking-exp-01-21 (Gemini 2.5 Flash Preview 04-17) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-flash-thinking-exp (Gemini 2.5 Flash Preview 04-17) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.0-flash-thinking-exp-1219 (Gemini 2.5 Flash Preview 04-17) | [Actions: generateContent, countTokens, createCachedContent, batchGenerateContent]\n",
      "- models/gemini-2.5-flash-preview-tts (Gemini 2.5 Flash Preview TTS) | [Actions: countTokens, generateContent]\n",
      "- models/gemini-2.5-pro-preview-tts (Gemini 2.5 Pro Preview TTS) | [Actions: countTokens, generateContent]\n",
      "- models/learnlm-2.0-flash-experimental (LearnLM 2.0 Flash Experimental) | [Actions: generateContent, countTokens]\n",
      "- models/gemma-3-1b-it (Gemma 3 1B) | [Actions: generateContent, countTokens]\n",
      "- models/gemma-3-4b-it (Gemma 3 4B) | [Actions: generateContent, countTokens]\n",
      "- models/gemma-3-12b-it (Gemma 3 12B) | [Actions: generateContent, countTokens]\n",
      "- models/gemma-3-27b-it (Gemma 3 27B) | [Actions: generateContent, countTokens]\n",
      "- models/gemma-3n-e4b-it (Gemma 3n E4B) | [Actions: generateContent, countTokens]\n",
      "- models/embedding-001 (Embedding 001) | [Actions: embedContent]\n",
      "- models/text-embedding-004 (Text Embedding 004) | [Actions: embedContent]\n",
      "- models/gemini-embedding-exp-03-07 (Gemini Embedding Experimental 03-07) | [Actions: embedContent, countTextTokens, countTokens]\n",
      "- models/gemini-embedding-exp (Gemini Embedding Experimental) | [Actions: embedContent, countTextTokens, countTokens]\n",
      "- models/aqa (Model that performs Attributed Question Answering.) | [Actions: generateAnswer]\n",
      "- models/imagen-3.0-generate-002 (Imagen 3.0 002 model) | [Actions: predict]\n",
      "- models/veo-2.0-generate-001 (Veo 2) | [Actions: predictLongRunning]\n",
      "- models/gemini-2.5-flash-preview-native-audio-dialog (Gemini 2.5 Flash Preview Native Audio Dialog) | [Actions: countTokens, bidiGenerateContent]\n",
      "- models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3 (Gemini 2.5 Flash Preview Native Audio Dialog RAI v3) | [Actions: countTokens, bidiGenerateContent]\n",
      "- models/gemini-2.5-flash-exp-native-audio-thinking-dialog (Gemini 2.5 Flash Exp Native Audio Thinking Dialog) | [Actions: countTokens, bidiGenerateContent]\n",
      "- models/gemini-2.0-flash-live-001 (Gemini 2.0 Flash 001) | [Actions: bidiGenerateContent, countTokens]\n"
     ]
    }
   ],
   "source": [
    "const models = await ai.models.list();\n",
    "let { page } = models;\n",
    "while (page.length > 0) {\n",
    "  for (const model of page) {\n",
    "    console.log(`- ${model.name} (${model.displayName}) | [Actions: ${model.supportedActions?.join(\", \")}]`);\n",
    "  }\n",
    "  page = models.hasNextPage() ? await models.nextPage() : [];\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models support `embedContent`, used for embeddings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- models/embedding-001 (Embedding 001) | [Actions: embedContent]\n",
      "- models/text-embedding-004 (Text Embedding 004) | [Actions: embedContent]\n",
      "- models/gemini-embedding-exp-03-07 (Gemini Embedding Experimental 03-07) | [Actions: embedContent, countTextTokens, countTokens]\n",
      "- models/gemini-embedding-exp (Gemini Embedding Experimental) | [Actions: embedContent, countTextTokens, countTokens]\n"
     ]
    }
   ],
   "source": [
    "const models_1 = await ai.models.list();\n",
    "let page_1 = models_1.page;\n",
    "while (page_1.length > 0) {\n",
    "  for (const model of page_1) {\n",
    "    if (model.supportedActions?.includes(\"embedContent\")) {\n",
    "      console.log(`- ${model.name} (${model.displayName}) | [Actions: ${model.supportedActions.join(\", \")}]`);\n",
    "    }\n",
    "  }\n",
    "  page_1 = models_1.hasNextPage() ? await models_1.nextPage() : [];\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find details about a model\n",
    "\n",
    "You can see more details about a model, including the `inputTokenLimit` and `outputTokenLimit` as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"models/gemini-2.0-flash\",\n",
      "  \"displayName\": \"Gemini 2.0 Flash\",\n",
      "  \"description\": \"Gemini 2.0 Flash\",\n",
      "  \"version\": \"2.0\",\n",
      "  \"tunedModelInfo\": {},\n",
      "  \"inputTokenLimit\": 1048576,\n",
      "  \"outputTokenLimit\": 8192,\n",
      "  \"supportedActions\": [\n",
      "    \"generateContent\",\n",
      "    \"countTokens\",\n",
      "    \"createCachedContent\",\n",
      "    \"batchGenerateContent\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "const models_2 = await ai.models.list();\n",
    "let page_2 = models_2.page;\n",
    "while (page_2.length > 0) {\n",
    "  for (const model of page_2) {\n",
    "    if (model.name === \"models/gemini-2.0-flash\") {\n",
    "      console.log(JSON.stringify(model, null, 2));\n",
    "    }\n",
    "  }\n",
    "  page_2 = models_2.hasNextPage() ? await models_2.nextPage() : [];\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning more\n",
    "\n",
    "- To learn how use a model for prompting, see the [Prompting](Prompting.ipynb) quickstart.\n",
    "- To learn how use a model for embedding, see the [Embedding](Embeddings.ipynb) quickstart.\n",
    "- For more information on models, visit the [Gemini models](https://ai.google.dev/models/gemini) documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
