{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini API: Embeddings Quickstart\n",
    "\n",
    "The Gemini API generates state-of-the-art text embeddings. An embedding is a list of floating point numbers that represent the meaning of a word, sentence, or paragraph. You can use embeddings in many downstream applications like document search.\n",
    "\n",
    "This notebook provides quick code examples that show you how to get started generating embeddings.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install the Google GenAI SDK\n",
    "\n",
    "Install the Google GenAI SDK from [npm](https://www.npmjs.com/package/@google/genai). \n",
    "\n",
    "```bash\n",
    "$ npm install @google/genai\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup your API key\n",
    "\n",
    "You can [create](https://aistudio.google.com/app/apikey) your API key using Google AI Studio with a single click.\n",
    "\n",
    "Remember to treat your API key like a password. Don't accidentally save it in a notebook or source file you later commit to GitHub. In this notebook we will be storing the API key in a `.env` file. You can also set it as an environment variable or use a secret manager. \n",
    "\n",
    "Here's how to set it up in a `.env` file:\n",
    "\n",
    "```bash\n",
    "$ touch .env\n",
    "$ echo \"GEMINI_API_KEY=<YOUR_API_KEY>\" >> .env\n",
    "```\n",
    "\n",
    ":::{.callout-tip}\n",
    "\n",
    "Another option is to set the API key as an environment variable. You can do this in your terminal with the following command:\n",
    "\n",
    "```bash\n",
    "$ export GEMINI_API_KEY=\"<YOUR_API_KEY>\"\n",
    "```\n",
    ":::\n",
    "\n",
    "### Load the API key\n",
    "\n",
    "To load the API key from the `.env` file, we will use the `dotenv` package. This package loads environment variables from a `.env` file into `process.env`. \n",
    "\n",
    "```bash\n",
    "$ npm install dotenv\n",
    "```\n",
    "\n",
    "Then, we can load the API key in our code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY is set in the environment variables\n"
     ]
    }
   ],
   "source": [
    "const dotenv = require(\"dotenv\") as typeof import(\"dotenv\");\n",
    "\n",
    "dotenv.config({\n",
    "  path: \"../.env\",\n",
    "});\n",
    "\n",
    "const GEMINI_API_KEY = process.env.GEMINI_API_KEY ?? \"\";\n",
    "if (!GEMINI_API_KEY) {\n",
    "  throw new Error(\"GEMINI_API_KEY is not set in the environment variables\");\n",
    "}\n",
    "console.log(\"GEMINI_API_KEY is set in the environment variables\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "In our particular case the `.env` is is one directory up from the notebook, hence we need to use `../` to go up one directory. If the `.env` file is in the same directory as the notebook, you can omit it altogether. \n",
    "\n",
    "```\n",
    "│\n",
    "├── .env\n",
    "└── quickstarts\n",
    "    └── Embeddings.ipynb\n",
    "```\n",
    ":::\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize SDK Client\n",
    "\n",
    "With the new SDK, now you only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "const google = require(\"@google/genai\") as typeof import(\"@google/genai\");\n",
    "\n",
    "const ai = new google.GoogleGenAI({ apiKey: GEMINI_API_KEY });\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model\n",
    "\n",
    "Now select the model you want to use in this guide, since this an embeddings quickstart, we will use the `text-embeddings-004` model. Text embeddings are used to measure the relatedness of strings and are widely used in many AI applications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "const tslab = require(\"tslab\") as typeof import(\"tslab\");\n",
    "\n",
    "const MODEL_ID = \"text-embedding-004\";\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed content\n",
    "\n",
    "Call the `embedContent` method with the `models/text-embedding-004` model to generate text embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings: [\n",
      "    0.013168517,   -0.00871193,  -0.046782672,\n",
      "  0.00069969177,  -0.009518872,  -0.008720178,\n",
      "     0.06010358,   0.024755737,   0.026053527,\n",
      "    0.054356426,   -0.03793384, -0.0014235445,\n",
      "    0.030605137,  -0.015512642,  -0.012904964,\n",
      "    -0.02880739,  -0.007819577,   0.012152762,\n",
      "     -0.1139952,   0.010654231,   0.005365246,\n",
      "   -0.001178891,  -0.029781109,  -0.060107403,\n",
      "   -0.015272871, -0.0036046242,   0.006147686,\n",
      "    0.031175768,   0.021421982,    0.03710434,\n",
      "   -0.037202735,   0.046146937,   0.002196372,\n",
      "   -0.031793054,   0.009660255,   0.012500477,\n",
      "     -0.0509635,     0.0211728,   0.014332891,\n",
      "   -0.057802226,  -0.027034516,    0.03680537,\n",
      "   0.0016361808,     0.0085209,    0.04331588,\n",
      "   -0.032519087,   0.018076202, -0.0031592466,\n",
      "   0.0045996527, -0.0063372543\n",
      "] ...TRIMMED\n"
     ]
    }
   ],
   "source": [
    "const text_embeddings = await ai.models.embedContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: [\"Hello world\"],\n",
    "});\n",
    "console.log(\"Text Embeddings:\", text_embeddings.embeddings?.[0].values?.slice(0, 50), \"...TRIMMED\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Embeddings Length: 768\n"
     ]
    }
   ],
   "source": [
    "console.log(\"Text Embeddings Length:\", text_embeddings.embeddings?.[0].values?.length);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch embed content\n",
    "\n",
    "You can embed a list of multiple prompts with one API call for efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Text Embeddings: [\n",
      "  [\n",
      "     -0.010632273,  0.019375853,    0.020965198,\n",
      "     0.0007706437, -0.061464068,    0.014739741,\n",
      "    -0.0022759985,  0.013184195,    0.014464715,\n",
      "      0.022593116,   0.02184836,   -0.059616957,\n",
      "       0.06032222, -0.047657482,    0.017848385,\n",
      "      -0.10987464,   -0.0598155,    -0.00479664,\n",
      "     -0.043298274,  -0.05090505,    0.029398112,\n",
      "      0.011642447,   0.04183789,   -0.017999396,\n",
      "      0.011026355,  0.049722955,    0.012025892,\n",
      "      0.007331535,   0.01967245,  -0.0025621902,\n",
      "      0.028765293, 0.0068937168,   0.0029231338,\n",
      "    -0.0002095079,  0.032031864,     0.02518659,\n",
      "     -0.032855466,   0.00758291, -0.00011585959,\n",
      "     -0.034515556, -0.066151336,     0.03191643,\n",
      "     -0.026680378,  0.017334407,   -0.025778342,\n",
      "     -0.008119435, -0.002431255,   -0.009850676,\n",
      "     -0.030725427,   0.08225489\n",
      "  ],\n",
      "  [\n",
      "     0.018468002,  0.0054281265,  -0.017658807,\n",
      "     0.013859263,    0.05341865,   0.041700866,\n",
      "     0.031085702,   -0.06442814,   0.010460507,\n",
      "     0.006893959,  -0.049074043,   0.015438477,\n",
      "      0.02833025,   0.041007824,  0.0016454521,\n",
      "     -0.07597325,   0.019856492, -0.0065018134,\n",
      "     -0.04790915,   0.007798852,  0.0059981374,\n",
      "     0.007498053, -0.0077681113, 0.00089508423,\n",
      "      0.02067591,   0.014558769,   0.048106413,\n",
      "    -0.035838168, -0.0076576024,  -0.025036177,\n",
      "     0.038854446,   0.040672384,   0.018866174,\n",
      "     -0.09118198,   0.043987993,    0.09125325,\n",
      "    -0.019055402,   0.058025226,     0.0337241,\n",
      "    -0.007700461,  -0.051549293,   0.033333547,\n",
      "     -0.04249377,   0.036880627,   0.030723767,\n",
      "    -0.010024755,  -0.039599802,    0.04335347,\n",
      "    -0.013405023,   0.027561612\n",
      "  ],\n",
      "  [\n",
      "     0.058089074,   0.020941732,   -0.10872878,\n",
      "     -0.04039259,  -0.044404425,   0.008074058,\n",
      "     0.029530387,    0.06106795,  -0.040581264,\n",
      "    0.0076176887,  -0.052324653, -0.0017251427,\n",
      "     0.011229625,  -0.022567088,  -0.039304733,\n",
      "     -0.06767425,   0.050662234,  -0.043872133,\n",
      "     -0.06564835, -0.0030828284,   0.031009678,\n",
      "     -0.06744081,   -0.02735545,   -0.04357851,\n",
      "    -0.015614915,   0.021484021,    0.02469868,\n",
      "    -0.022331946,  -0.027676083,   0.000084142,\n",
      "     0.033065446,   0.008663191,   0.010000569,\n",
      "     -0.03285902,   0.025153043,   -0.07011023,\n",
      "    -0.021991147,   -0.05085551,   0.033521175,\n",
      "     -0.06584735,  -0.045584362,  -0.027165776,\n",
      "    -0.025329018,    0.03824336,  -0.036927626,\n",
      "     0.062992625,   0.004152124,   0.049990047,\n",
      "    -0.016771948,    0.02209841\n",
      "  ]\n",
      "] ...TRIMMED\n"
     ]
    }
   ],
   "source": [
    "const batch_embeddings = await ai.models.embedContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: [\"What is the meaning of life?\", \"How much wood would a woodchuck chuck?\", \"How does the brain work?\"],\n",
    "});\n",
    "console.log(\n",
    "  \"Batch Text Embeddings:\",\n",
    "  batch_embeddings.embeddings?.map((e) => e.values?.slice(0, 50)),\n",
    "  \"...TRIMMED\"\n",
    ");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncating embeddings\n",
    "\n",
    "The `text-embedding-004` model also supports lower embedding dimensions. Specify `outputDimensionality` to truncate the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated Text Embeddings: [\n",
      "   0.013168517,   -0.00871193,\n",
      "  -0.046782672, 0.00069969177,\n",
      "  -0.009518872,  -0.008720178,\n",
      "    0.06010358,   0.024755737,\n",
      "   0.026053527,   0.054356426\n",
      "]\n",
      "Truncated Text Embeddings Length: 10\n"
     ]
    }
   ],
   "source": [
    "const trucated_embeddings = await ai.models.embedContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: [\"Hello world\"],\n",
    "  config: {\n",
    "    outputDimensionality: 10,\n",
    "  },\n",
    "});\n",
    "console.log(\"Truncated Text Embeddings:\", trucated_embeddings.embeddings?.[0].values);\n",
    "console.log(\"Truncated Text Embeddings Length:\", trucated_embeddings.embeddings?.[0].values?.length);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify `taskType`\n",
    "\n",
    "For details on how to call `embedContent`, check out the [Embeddings API reference](https://ai.google.dev/api/embeddings#method:-models.embedcontent), including the section on `taskType`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With No Task Type Text Embeddings: [\n",
      "    0.013168517,   -0.00871193,  -0.046782672,\n",
      "  0.00069969177,  -0.009518872,  -0.008720178,\n",
      "     0.06010358,   0.024755737,   0.026053527,\n",
      "    0.054356426,   -0.03793384, -0.0014235445,\n",
      "    0.030605137,  -0.015512642,  -0.012904964,\n",
      "    -0.02880739,  -0.007819577,   0.012152762,\n",
      "     -0.1139952,   0.010654231,   0.005365246,\n",
      "   -0.001178891,  -0.029781109,  -0.060107403,\n",
      "   -0.015272871, -0.0036046242,   0.006147686,\n",
      "    0.031175768,   0.021421982,    0.03710434,\n",
      "   -0.037202735,   0.046146937,   0.002196372,\n",
      "   -0.031793054,   0.009660255,   0.012500477,\n",
      "     -0.0509635,     0.0211728,   0.014332891,\n",
      "   -0.057802226,  -0.027034516,    0.03680537,\n",
      "   0.0016361808,     0.0085209,    0.04331588,\n",
      "   -0.032519087,   0.018076202, -0.0031592466,\n",
      "   0.0045996527, -0.0063372543\n",
      "] ...TRIMMED\n",
      "With Task Type Text Embeddings: [\n",
      "   0.023399517,  -0.008547142, -0.052534223,\n",
      "  -0.012143115,  0.0055042417, -0.001007702,\n",
      "   0.028462889,   0.037563253, -0.023794618,\n",
      "   0.045095872,  -0.014744246, 0.0034827266,\n",
      "    0.07847462, -0.0088950405, -0.008143913,\n",
      "  -0.045579128,   0.017674835,  0.010504201,\n",
      "   -0.11951811,   0.025116991,   0.02234638,\n",
      "  -0.031670354,   0.009702842, -0.011191917,\n",
      "  -0.020584144,   -0.01684894, -0.000543171,\n",
      "   0.003336858, -0.0024763693,  0.018954858,\n",
      "    0.03398058,    0.07639708, 0.0037753258,\n",
      "  -0.055841617,    0.01699452,  0.011088602,\n",
      "  -0.016603941,    0.03163179,  0.039773043,\n",
      "   -0.04514968,   -0.07688451,  0.030634686,\n",
      "  -0.003726261,   0.042314958,  0.014746045,\n",
      "   -0.03570954,  -0.008157468,  0.026814101,\n",
      "  -0.031223731,   0.022471815\n",
      "] ...TRIMMED\n"
     ]
    }
   ],
   "source": [
    "const with_no_task_type = await ai.models.embedContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: [\"Hello world\"],\n",
    "});\n",
    "console.log(\"With No Task Type Text Embeddings:\", with_no_task_type.embeddings?.[0].values?.slice(0, 50), \"...TRIMMED\");\n",
    "\n",
    "const with_task_type = await ai.models.embedContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: [\"Hello world\"],\n",
    "  config: {\n",
    "    taskType: \"retrieval_document\",\n",
    "  },\n",
    "});\n",
    "console.log(\"With Task Type Text Embeddings:\", with_task_type.embeddings?.[0].values?.slice(0, 50), \"...TRIMMED\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning more\n",
    "\n",
    "Check out these examples in the Cookbook to learn more about what you can do with embeddings:\n",
    "\n",
    "* [Search Reranking](../examples/Search_reranking_using_embeddings.ipynb): Use embeddings from the Gemini API to rerank search results from Wikipedia.\n",
    "\n",
    "* [Anomaly detection with embeddings](../examples/Anomaly_detection_with_embeddings.ipynb): Use embeddings from the Gemini API to detect potential outliers in your dataset.\n",
    "\n",
    "* [Train a text classifier](../examples/Classify_text_with_embeddings.ipynb): Use embeddings from the Gemini API to train a model that can classify different types of newsgroup posts based on the topic.\n",
    "\n",
    "* Embeddings have many applications in Vector Databases, too. Check out this [example with Chroma DB](../examples/chromadb/Vectordb_with_chroma.ipynb).\n",
    "\n",
    "You can learn more about embeddings in general on ai.google.dev in the [embeddings guide](https://ai.google.dev/docs/embeddings_guide)\n",
    "\n",
    "* You can find additional code examples with the JS SDK [here](https://ai.google.dev/gemini-api/docs/quickstart#javascript).\n",
    "\n",
    "* You can also find more details in the API Reference for [embedContent](https://ai.google.dev/api/rest/v1/models/embedContent) and [batchEmbedContents](https://ai.google.dev/api/rest/v1/models/batchEmbedContents)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
