{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini API: Getting started with information grounding for Gemini models\n",
    "\n",
    "In this notebook you will learn how to use information grounding with [Gemini models](https://ai.google.dev/gemini-api/docs/models/).\n",
    "\n",
    "Information grounding is the process of connecting these models to specific, verifiable information sources to enhance the accuracy, relevance, and factual correctness of their responses. While LLMs are trained on vast amounts of data, this knowledge can be general, outdated, or lack specific context for particular tasks or domains. Grounding helps to bridge this gap by providing the LLM with access to curated, up-to-date information.\n",
    "\n",
    "Here you will experiment with:\n",
    "\n",
    "- Grounding information using Google Search grounding\n",
    "- Adding YouTube links to gather context information to your prompt\n",
    "- Using URL context to include website URL as context to your prompt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install the Google GenAI SDK\n",
    "\n",
    "Install the Google GenAI SDK from [npm](https://www.npmjs.com/package/@google/genai). \n",
    "\n",
    "```bash\n",
    "$ npm install @google/genai\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup your API key\n",
    "\n",
    "You can [create](https://aistudio.google.com/app/apikey) your API key using Google AI Studio with a single click.\n",
    "\n",
    "Remember to treat your API key like a password. Don't accidentally save it in a notebook or source file you later commit to GitHub. In this notebook we will be storing the API key in a `.env` file. You can also set it as an environment variable or use a secret manager. \n",
    "\n",
    "Here's how to set it up in a `.env` file:\n",
    "\n",
    "```bash\n",
    "$ touch .env\n",
    "$ echo \"GEMINI_API_KEY=<YOUR_API_KEY>\" >> .env\n",
    "```\n",
    "\n",
    ":::{.callout-tip}\n",
    "\n",
    "Another option is to set the API key as an environment variable. You can do this in your terminal with the following command:\n",
    "\n",
    "```bash\n",
    "$ export GEMINI_API_KEY=\"<YOUR_API_KEY>\"\n",
    "```\n",
    ":::\n",
    "\n",
    "### Load the API key\n",
    "\n",
    "To load the API key from the `.env` file, we will use the `dotenv` package. This package loads environment variables from a `.env` file into `process.env`. \n",
    "\n",
    "```bash\n",
    "$ npm install dotenv\n",
    "```\n",
    "\n",
    "Then, we can load the API key in our code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY is set in the environment variables\n"
     ]
    }
   ],
   "source": [
    "const dotenv = require(\"dotenv\") as typeof import(\"dotenv\");\n",
    "\n",
    "dotenv.config({\n",
    "  path: \"../.env\",\n",
    "});\n",
    "\n",
    "const GEMINI_API_KEY = process.env.GEMINI_API_KEY ?? \"\";\n",
    "if (!GEMINI_API_KEY) {\n",
    "  throw new Error(\"GEMINI_API_KEY is not set in the environment variables\");\n",
    "}\n",
    "console.log(\"GEMINI_API_KEY is set in the environment variables\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "In our particular case the `.env` is is one directory up from the notebook, hence we need to use `../` to go up one directory. If the `.env` file is in the same directory as the notebook, you can omit it altogether. \n",
    "\n",
    "```\n",
    "\u2502\n",
    "\u251c\u2500\u2500 .env\n",
    "\u2514\u2500\u2500 quickstarts\n",
    "    \u2514\u2500\u2500 Grounding.ipynb\n",
    "```\n",
    ":::\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize SDK Client\n",
    "\n",
    "With the new SDK, now you only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "const google = require(\"@google/genai\") as typeof import(\"@google/genai\");\n",
    "\n",
    "const ai = new google.GoogleGenAI({ apiKey: GEMINI_API_KEY });\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model\n",
    "\n",
    "Now select the model you want to use in this guide, either by selecting one in the list or writing it down. Keep in mind that some models, like the 2.5 ones are thinking models and thus take slightly more time to respond (cf. [thinking notebook](Get_started_thinking.ipynb) for more details and in particular learn how to switch the thiking off).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "const tslab = require(\"tslab\") as typeof import(\"tslab\");\n",
    "\n",
    "const MODEL_ID = \"gemini-2.5-flash-preview-05-20\";\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Google Search grounding\n",
    "\n",
    "Google Search grounding is particularly useful for queries that require current information or external knowledge. Using Google Search, Gemini can access nearly real-time information and better responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The latest Indian Premier League (IPL) match was the IPL 2025 Final, played on June 3, 2025, in Ahmedabad.\n",
       "\n",
       "Royal Challengers Bengaluru (RCB) won the match against Punjab Kings (PBKS) by 6 runs, securing their maiden IPL title. Virat Kohli was emotional after RCB's historic win. Krunal Pandya was named the Man of the Match for his economical bowling performance."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Query: [\n",
      "  \"latest Indian Premier League match\",\n",
      "  \"who won the latest IPL match\",\n",
      "  \"IPL 2025 latest match\"\n",
      "]\n",
      "Search Pages: [\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHt5kdqdKChCOa4Pr_VPq-gkhoamwHE_iJ7o5RjLXIZzeI8TlkXQAR1XQHWyRNevZPTZteSGYR_ktkeCXuaJNMzEtiY1vDOiYAqqwRHmf-0khw3lJECXDBYSMcf6EWuAY1ClUwt7u3TE77DH8qSQYstjGe7dmNu8vUX\",\n",
      "      \"title\": \"indiatimes.com\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFCh5VcEGh9Ppqbg8BuGhf2X6LdqlJu9t5zENDQxiarqynpQBAcWuAJgCxLJxkhc223LqJDgX5VVrqUD-9LLks_RJT8OUwTLUnpLH2Ik8doMHLfo54eI5AlWXNiWQHqMXCbmJRBbhBIu1sUuyuS4O7h9SR4VQvO4aun6b--Z2Tci0mGK_1VAJA_Nq-3_FNih6pXFq3Fv1Q8aBCc9ej_pB6g9M4f6EcWKKO2hs-oaKzR3BefFnnWrKYSri7iel8au4UEcPvgkCPBjdLPz-yFkM1apJvTvbUduUXfhGCvDuRDwfFEsoyT_7IdM9YhaXo=\",\n",
      "      \"title\": \"hindustantimes.com\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGvvHqeHxsXknsFovCD7wo_veKNQ6iYuWG9DskR4DJ6snVn3D8SnMM87g4L18UaMAO7r2Awtm38AOyarUmOmJl0-8WEOKoRokRnclqUow5wXIXYiEkppq8QXHQvmdGUmGsnqtNBD8ihXgEZsTKjADNFvAbcHAi1KAqreLNSwRUrZJeZZuyh8Q4cmP-sQr641mN93E-U8-brpV0sioq8BTxjGjqOBygrtiVK50ii1_T331e-zV0C43LEuseCLnGK2EhcgDVwr3sTBWYBBGPpayIMUHF5YiKLvginlkqaVsljdJg2PRtarWaZM2tmNMWVe5tAw7arRDyU4l0J_0s=\",\n",
      "      \"title\": \"economictimes.com\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHmjQGwwY0-0xsbJwE6Iiq0YeANNMylO8O7QqED6QR0DjWMPWKCVJ7BbFlCtjpnNixJqtuNHhaZnxX7Dm9wpvxATPJ4VcZHG3_bR5gvgWIcN815qb90gvYjQdvgZWfp9O974BgMbTMZPZTuX-Bh\",\n",
      "      \"title\": \"hindustantimes.com\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEUFnrVepN1H1fgVoziCx8PvUEv8DNW5sY_yi6nfJZmYkgXZZ8grAr3f-Xem__PJGjLLj-tWs7H3RPDym3dLiwculxhndrCJiMmLR05FAqHAkOeKWP4rTTOtfInazSk0kZCgrRS3w==\",\n",
      "      \"title\": \"thehindu.com\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEM79AM748uZRyPEo299owu6dh5IWJvZ9zN2r9Hsvqze0jlz3qWdydYu77QE_pTR68fleN_TvnWelgL3bay37V8im1EmRsYKQ6waMkotgEma4D_BoRwMSU2G6tHyfuwdc6kVTA0OMdbp-0tyQz25UI9r2Trrl8upNhY5Ghlc1N8sUdlS36fvFv9pzMvAXnlMCU=\",\n",
      "      \"title\": \"jagranjosh.com\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGXhGLM_mklCri2YB0fS1v_xpfcTItWFFBMRSCIf6MYzMwhs8ebT9nDdMq1PL8pa0OwKcL50rcD5qZ-N2ShSQsI14HQ8XifZy5lQPpLOKwACpHWkkDQPQge0EXAzO2vWzsEwWkpbW6Xd0UqeO8tiMoUZR0J8jg8NHUiatz14S2rdYoiX_szYkRCNRw0e_0=\",\n",
      "      \"title\": \"olympics.com\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGyyx6UMCzkXbOfQYKW6vf99hvJrupL4nB-46oHtG-n79CcqG7bP6Yw0OCF5hjcwmc5TJG2YzBR7Cr2v9KPApOFm_Cl8AbFTwzxy-A3K6mfixgF6mkGYOeubi-HGVcf_IhSvECdhleOapVK\",\n",
      "      \"title\": \"careerpower.in\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEomdtJaCbrT3KBtlXb1bzxqBz3dQpRn34LgUhKW-wM2Ds5fzsQK5PPOhIYD8DM7KQXCbnj8QZUE9C1fSTjmfHGI0ZujDFAgBiQ1q1woWKKIbKIkvtb-oofk69NW7oldahhbYOuR6fG77IRf2XPdcBS-8eDkZy5blZUeQf3S4L17qrH_p_juMQ=\",\n",
      "      \"title\": \"iplt20.com\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFy5Kqsj2xGuUhpX1ke2fxGT2vMaQVOKmHw1tbj2lBdYHhGwiSRvuDJWT0LSLVJeEaiiQvznnhNjBI8hZDHrMOEb7BY5BC8ZQYNNfBlOzAMf0hl4IAyOWuBUoGFwLiUPDePxjcONn04NUk0xz0HW287t3-Pkw6_1YWqoR7yp9nhxUt5PBNksSv2jvHq1IenmG1wis9015IQ\">IPL 2025 latest match</a>\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXBx7m50RFMJnXajOMf4SvUn7TNR3V3CnDIAWY4zmrVc7KwPsewZV2-Sy0jO34jUT6rBE9rMjZlzbtVOa2N3M-qCw5isLYNCN1uU73XNiDopdzWIA2C1fyTOF4-Cb84UG-Q2hMV3Yj3pl_ZAqbHmSSrBDrxAOPDAunWYX9OPtyx-kouYjoxELOHaARVmecfYTy5RE89cG7xfpgS9Pg21Lm3hSw6Q==\">latest Indian Premier League match</a>\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG_Do8CHZXNoDyjo7-pYDAqgadSn2mFz4pJlAyfzH4T4jmHhs0Ju_LujLeKGimNVcZFrbL2f56UpljthrkRRU5z45tY_2dYiK1VKNyfhdzMCXDAefEJ6ydJq0vyAA0K0lnWAZvZH7AM597sdD6qx7i4OLHpaWg7HFeKH1vhLP7fG0e1OoO9bQi4bUYBPzfCKu_02EHQdyjN3ml1up-aSQ==\">who won the latest IPL match</a>\n",
       "  </div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const search_grounding = await ai.models.generateContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: \"What was the latest Indian Premier League match and who won?\",\n",
    "  config: {\n",
    "    tools: [{ googleSearch: {} }],\n",
    "  },\n",
    "});\n",
    "\n",
    "tslab.display.markdown(search_grounding.text ?? \"\");\n",
    "\n",
    "console.log(\n",
    "  \"Search Query:\",\n",
    "  JSON.stringify(search_grounding.candidates?.[0]?.groundingMetadata?.webSearchQueries, null, 2)\n",
    ");\n",
    "console.log(\n",
    "  \"Search Pages:\",\n",
    "  JSON.stringify(search_grounding.candidates?.[0]?.groundingMetadata?.groundingChunks, null, 2)\n",
    ");\n",
    "\n",
    "tslab.display.html(search_grounding.candidates?.[0]?.groundingMetadata?.searchEntryPoint?.renderedContent ?? \"\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that running the same prompt without search grounding gives you outdated information:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The latest Indian Premier League (IPL) match was the **Final of the 2024 season**, played on **May 26, 2024**.\n",
       "\n",
       "It was between:\n",
       "\n",
       "*   **Kolkata Knight Riders (KKR)**\n",
       "*   **Sunrisers Hyderabad (SRH)**\n",
       "\n",
       "**Kolkata Knight Riders (KKR) won** the match by 8 wickets, securing their third IPL title."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const without_search_grounding = await ai.models.generateContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: \"What was the latest Indian Premier League match and who won?\",\n",
    "});\n",
    "tslab.display.markdown(without_search_grounding.text ?? \"\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grounding with YouTube links\n",
    "\n",
    "you can directly include a public YouTube URL in your prompt. The Gemini models will then process the video content to perform tasks like summarization and answering questions about the content.\n",
    "\n",
    "This capability leverages Gemini's multimodal understanding, allowing it to analyze and interpret video data alongside any text prompts provided.\n",
    "\n",
    "You do need to explicitly declare the video URL you want the model to process as part of the contents of the request. Here a simple interaction where you ask the model to summarize a YouTube video:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This video introduces \"Gemma Chess,\" showcasing how Google's Gemma AI model can bring a \"new dimension\" to the game of chess. Ju-yeong Ji from Google DeepMind explains that Gemma isn't designed to replace powerful, calculative chess engines like Stockfish (which excel at finding optimal moves) but rather to enhance the chess experience through its language understanding and generation capabilities.\n",
       "\n",
       "Gemma offers several key applications:\n",
       "\n",
       "1.  **Game Analysis & Explanations:** It can analyze chess games (using PGN data) and explain the strategic and tactical significance of moves in natural language, providing insights into *why* certain moves are interesting or impactful, even considering psychological aspects for human players.\n",
       "2.  **Storytelling:** Gemma can transform game data into engaging narratives, bringing historical matches or personal games to life with descriptive language and emotional context.\n",
       "3.  **Chess Learning Support:** It acts as a \"smart study buddy,\" capable of explaining complex chess concepts (like openings such as the \"Sicilian Defense\" or specific tactical ideas like a \"passed pawn\") in detail, adapting the explanation to the user's skill level, and supporting multiple languages. It can also offer feedback on a player's understanding.\n",
       "\n",
       "Essentially, Gemma combines the precise computational strength of traditional chess AI with its own ability to interpret and communicate complex information in a human-like way, making chess learning and analysis more intuitive and accessible for everyone."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const YOUTUBE_URL = \"https://www.youtube.com/watch?v=XV1kOFo1C8M\";\n",
    "\n",
    "const youtube_grounding = await ai.models.generateContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: [\"Summarize this video.\", google.createPartFromUri(YOUTUBE_URL, \"video/x-youtube\")],\n",
    "});\n",
    "tslab.display.markdown(youtube_grounding.text ?? \"\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can also use the link as the source of truth for your request. In this example, you will first ask how Gemma models can help on chess games:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Gemma models, as Large Language Models (LLMs) developed by Google, are primarily designed for natural language understanding and generation. This means they operate on text, not directly on the board state, moves, or strategic calculations like a traditional chess engine (e.g., Stockfish, AlphaZero).\n",
       "\n",
       "Therefore, Gemma models *cannot* play chess, calculate moves, or evaluate positions with the accuracy and depth of dedicated chess engines.\n",
       "\n",
       "However, they *can* be incredibly helpful in chess games and study in **indirect, linguistic, and informational ways**:\n",
       "\n",
       "1.  **Learning and Education:**\n",
       "    *   **Explaining Rules and Concepts:** Ask Gemma to explain what a \"fork,\" \"pin,\" \"discovered attack,\" or \"zugzwang\" is. It can provide clear, concise definitions and examples.\n",
       "    *   **Teaching Openings:** It can describe common opening principles, explain the ideas behind specific openings (e.g., \"What are the main ideas in the Ruy Lopez?\"), and list common variations.\n",
       "    *   **Analyzing Puzzles and Positions (Textual):** You can describe a position (e.g., \"White to move, King on g1, Queen on d1, Rook on a1... can White win?\") and ask for a general strategic idea or what a good move *might* be, based on common chess principles it learned from its training data. It won't calculate precisely but can offer high-level advice.\n",
       "    *   **Creating Study Plans:** You could ask for a beginner's study plan, topics to focus on, or recommendations for improving specific aspects of your game.\n",
       "\n",
       "2.  **Game Analysis and Commentary (Prose):**\n",
       "    *   **Explaining Game Phases:** Ask it to describe what typically happens in the opening, middlegame, and endgame.\n",
       "    *   **Generating Commentary:** Provide a sequence of moves (in algebraic notation) and ask Gemma to generate natural language commentary, explaining what's happening or the likely intent behind moves.\n",
       "    *   **Summarizing Games:** Give it a PGN (Portable Game Notation) or a list of moves, and it can try to summarize the key moments, strategic themes, or turning points.\n",
       "    *   **Translating Chess Notation:** Convert algebraic notation into natural language descriptions, e.g., \"e4 e5 Nf3 Nc6\" -> \"White moves their king's pawn two squares, Black responds similarly, then White develops their knight to f3, and Black develops their knight to c6.\"\n",
       "\n",
       "3.  **Content Creation:**\n",
       "    *   **Writing Articles and Blogs:** Generate outlines or draft content for articles about chess history, famous players, specific openings, or strategic concepts.\n",
       "    *   **Creating Quizzes:** Ask it to generate multiple-choice questions about chess rules, history, or basic tactics.\n",
       "    *   **Scripting Videos:** Help draft scripts for chess lessons or game analysis videos.\n",
       "\n",
       "4.  **Historical and Conceptual Knowledge:**\n",
       "    *   **Recalling Famous Games/Players:** Ask about legendary matches, famous blunders, or the achievements of grandmasters.\n",
       "    *   **Understanding Chess Terminology:** Clarify the meaning of obscure or advanced chess terms.\n",
       "\n",
       "**Key Limitations to Remember:**\n",
       "\n",
       "*   **No Positional \"Understanding\":** Gemma models don't \"see\" the board or calculate moves like a chess engine. Their understanding is based on patterns and relationships in the text they were trained on.\n",
       "*   **No Tactical Depth:** They cannot calculate deep tactical lines, predict opponent responses accurately, or find the \"best\" move in a complex position.\n",
       "*   **Potential for Hallucination:** Like any LLM, Gemma can sometimes generate plausible-sounding but incorrect information, especially when asked for precise strategic or tactical advice that requires deep calculation.\n",
       "*   **Relies on Training Data:** Its knowledge is limited to what it learned from its vast text dataset. If a niche chess concept or a very recent game isn't in its training data, it won't know about it.\n",
       "\n",
       "In summary, Gemma models are fantastic **linguistic assistants** for chess. They can help you learn, explain, and create content *about* chess, but they are not a substitute for a dedicated chess engine when it comes to playing, calculating, or deep positional analysis."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const gemma_response = await ai.models.generateContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: \"How Gemma models can help on chess games?\",\n",
    "});\n",
    "tslab.display.markdown(gemma_response.text ?? \"\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you can ask the same question, now having the YouTube video as context to be used by the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Gemma models can help on chess games by bringing a \"new dimension\" to the experience, focusing on human understanding and interaction rather than solely on raw computational power. Here's how:\n",
       "\n",
       "1.  **Easier Chess Analysis and Explanations:**\n",
       "    *   **Demystifying Engine Output:** Traditional chess engines often provide technical numbers and complex move sequences that are hard for humans to understand. Gemma can take this technical data and translate it into plain, understandable text.\n",
       "    *   **Explaining Moves:** It can explain *why* a particular move is good, outlining the strategic ideas, tactical advantages, and potential dangers associated with it.\n",
       "    *   **Summarizing Complexities:** For intricate parts of a game, Gemma can summarize key tactical and strategic moments, helping players quickly grasp important takeaways.\n",
       "\n",
       "2.  **Storytelling and Narrative Generation:**\n",
       "    *   **Bringing Games to Life:** Gemma can analyze a chess game (including context like players and tournaments) and generate a compelling narrative about how the game unfolded. This makes reviewing past games a more engaging and immersive experience than just looking at move notation.\n",
       "    *   **Adding Context and Emotion:** It can imbue the game analysis with a \"backstory\" or emotional context, making the \"aha!\" moments of a game more impactful.\n",
       "\n",
       "3.  **Personalized Chess Learning and Coaching:**\n",
       "    *   **Intelligent Study Buddy:** Gemma can act as a personalized chess coach, explaining concepts like openings (e.g., the Sicilian Defense) in an easy-to-understand manner.\n",
       "    *   **Tailored Explanations:** It can adapt its explanations to the user's skill level (beginner, intermediate, advanced) and even provide them in different languages (e.g., Korean).\n",
       "    *   **Targeted Feedback:** Gemma can provide feedback on a player's understanding of chess ideas and point out areas where they might need to improve, making the learning process more efficient and personalized.\n",
       "\n",
       "4.  **Enhanced Interaction with Chess Engines:**\n",
       "    *   **Bridging AI and Human Understanding:** By combining the brute-force calculation strength of traditional chess AI (like AlphaZero) with Gemma's linguistic capabilities, it offers a more intuitive approach to learning and analyzing chess. It can interpret the engine's optimal moves and explain the underlying logic in a human-friendly way."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const gemma_grounding = await ai.models.generateContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: [\"How Gemma models can help on chess games?\", google.createPartFromUri(YOUTUBE_URL, \"video/x-youtube\")],\n",
    "});\n",
    "tslab.display.markdown(gemma_grounding.text ?? \"\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your answer is more insightful for the topic you want, using the knowledge shared on the video and not necessarily available on the model knowledge.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grounding information using URL context\n",
    "\n",
    "The URL Context tool empowers Gemini models to directly access and process content from specific web page URLs you provide within your API requests. This is incredibly interesting because it allows your applications to dynamically interact with live web information without needing you to manually pre-process and feed that content to the model.\n",
    "\n",
    "URL Context is effective because it allows the models to base its responses and analysis directly on the content of the designated web pages. Instead of relying solely on its general training data or broad web searches (which are also valuable grounding tools), URL Context anchors the model's understanding to the specific information present at those URLs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Gemini API offers various models optimized for different use cases, with Gemini 1.5, Gemini 2.0, and Gemini 2.5 representing different generations and capabilities. The key differences between the main variants are summarized in the table below.\n",
       "\n",
       "| Feature               | Gemini 1.5 Pro                                                                                                    | Gemini 1.5 Flash                                                                                                    | Gemini 2.0 Flash                                                                                                          | Gemini 2.5 Pro (Preview)                                                                                                 | Gemini 2.5 Flash (Preview)                                                                                                |\n",
       "| :-------------------- | :-------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------- |\n",
       "| **Primary Use Case / Optimization** | Mid-size multimodal model optimized for a wide range of reasoning tasks; excels at processing large amounts of data. | Fast and versatile multimodal model for scaling across diverse tasks.                                                    | Next-generation features and improved capabilities, superior speed, native tool use, built for agentic experiences.          | Most powerful thinking model with maximum response accuracy and state-of-the-art performance; best for complex coding, reasoning, and multimodal understanding. | Best model in terms of price-performance, offering well-rounded capabilities; ideal for low-latency, high-volume tasks requiring thinking. |\n",
       "| **Input Modalities**  | Audio, images, video, text                                                                                            | Audio, images, video, text                                                                                              | Audio, images, video, text                                                                                                    | Audio, images, video, text                                                                                                   | Audio, images, video, text                                                                                                  |\n",
       "| **Output Modalities** | Text                                                                                                                  | Text                                                                                                                    | Text                                                                                                                          | Text                                                                                                                         | Text                                                                                                                        |\n",
       "| **Input Token Limit** | 2,097,152 (2M)                                                                                                        | 1,048,576 (1M)                                                                                                          | 1,048,576 (1M)                                                                                                                | 1,048,576 (1M)                                                                                                               | 1,048,576 (1M)                                                                                                              |\n",
       "| **Key Capabilities**  | System instructions, JSON mode, JSON schema, adjustable safety settings, caching, function calling, code execution.     | System instructions, JSON mode, JSON schema, adjustable safety settings, caching, tuning, function calling, code execution. | Structured outputs, caching, function calling, code execution, search grounding, Live API. Thinking is experimental.         | Structured outputs, caching, function calling, code execution, search grounding, thinking.                                   | Adaptive thinking, cost efficiency, structured outputs, caching, function calling, code execution, search grounding, thinking. |\n",
       "| **Status**            | Latest Stable                                                                                                         | Latest Stable                                                                                                           | Latest Stable (also Experimental and Stable versions)                                                                         | Preview                                                                                                                      | Preview                                                                                                                     |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const url_context_response = await ai.models.generateContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: [\n",
    "    `\n",
    "    based on https://ai.google.dev/gemini-api/docs/models, what are the key\n",
    "    differences between Gemini 1.5, Gemini 2.0 and Gemini 2.5 models?\n",
    "    Create a markdown table comparing the differences.\n",
    "    `,\n",
    "  ],\n",
    "  config: {\n",
    "    tools: [{ urlContext: {} }],\n",
    "  },\n",
    "});\n",
    "tslab.display.markdown(url_context_response.text ?? \"\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reference, you can see how the answer would be without the URL context, using the official models documentation as reference:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "It seems there might be a slight misunderstanding regarding the versioning of Gemini models. As of my last update, **Google has not publicly released models named \"Gemini 2.0\" or \"Gemini 2.5.\"**\n",
       "\n",
       "The publicly announced and available Gemini models follow this progression:\n",
       "\n",
       "*   **Gemini 1.0 (Pro, Ultra, Nano):** The initial general release of the Gemini family.\n",
       "*   **Gemini 1.5 Pro:** A significant upgrade focusing on a massive context window and Mixture-of-Experts (MoE) architecture.\n",
       "*   **Gemini 1.5 Flash:** A faster, more cost-effective version of 1.5 Pro, optimized for high-volume, lower-latency tasks.\n",
       "\n",
       "Therefore, I will provide a comparison between **Gemini 1.0 (representing the initial family), Gemini 1.5 Pro, and Gemini 1.5 Flash**, as these are the relevant and distinct models in the Gemini lineup today.\n",
       "\n",
       "Here's a breakdown of their key differences:\n",
       "\n",
       "---\n",
       "\n",
       "## Comparison of Gemini Models (1.0 vs. 1.5 Pro vs. 1.5 Flash)\n",
       "\n",
       "| Feature            | Gemini 1.0 (Pro/Ultra/Nano)                                     | Gemini 1.5 Pro                                                      | Gemini 1.5 Flash                                                       |\n",
       "| :----------------- | :-------------------------------------------------------------- | :------------------------------------------------------------------ | :--------------------------------------------------------------------- |\n",
       "| **Release/Announced** | December 2023 (Pro/Ultra); Early 2024 (Nano)                   | February 2024 (Limited preview); May 2024 (Broader availability)    | May 2024 (Announced alongside 1.5 Pro's broader release)              |\n",
       "| **Primary Focus**  | Foundational multimodal capabilities, general-purpose reasoning | **Massive context window**, advanced long-context understanding     | **Speed & efficiency**, optimized for high-volume, low-latency tasks |\n",
       "| **Architecture**   | Highly optimized transformer architecture                      | Mixture-of-Experts (MoE)                                            | Mixture-of-Experts (MoE) (optimized for speed)                         |\n",
       "| **Context Window** | Up to 32K tokens (for Pro)                                      | **1 Million tokens** (default), expandable to 2 Million tokens      | **1 Million tokens** (default), expandable to 2 Million tokens      |\n",
       "| **Performance**    | Strong general reasoning, coding, multimodal understanding     | Exceptional long-document analysis, complex codebases, video analysis | High throughput, good for simpler tasks, less \"deep\" reasoning than 1.5 Pro |\n",
       "| **Cost/Efficiency**| Balanced                                                        | Higher cost per token due to advanced capabilities                  | Significantly **more cost-effective** and faster inference            |\n",
       "| **Modality**       | Multimodal (text, image, audio, video input/output)             | Multimodal (text, image, audio, video input/output)                 | Multimodal (text, image, audio, video input/output)                 |\n",
       "| **Ideal Use Cases**| Chatbots, content generation, general AI applications           | Summarizing entire books/videos, analyzing large datasets, complex troubleshooting, long-form code analysis | High-volume API calls, real-time chatbots, dynamic content updates, RAG without deep reasoning, quick summarization |\n",
       "| **Key Differentiator** | First publicly available, versatile Gemini family             | Unprecedented long-context processing for multimodal data           | Blazing speed and cost-efficiency for large-scale applications       |\n",
       "\n",
       "---\n",
       "\n",
       "**In summary:**\n",
       "\n",
       "*   **Gemini 1.0** established the baseline with strong general-purpose multimodal capabilities.\n",
       "*   **Gemini 1.5 Pro** represents a monumental leap in the **context window**, allowing it to process and understand vast amounts of information (like entire novels, lengthy codebases, or hours of video) in a single prompt. Its MoE architecture contributes to this capability.\n",
       "*   **Gemini 1.5 Flash** takes the MoE architecture from 1.5 Pro and optimizes it for **speed and cost-efficiency**, making it ideal for applications requiring high throughput where the deepest reasoning of 1.5 Pro isn't strictly necessary. It retains the same large context window as 1.5 Pro.\n",
       "\n",
       "It's possible that \"Gemini 2.0\" or \"Gemini 2.5\" refers to future internal development versions that have not yet been announced publicly. Google frequently iterates and develops models, and future major versions will undoubtedly bring even more advanced capabilities."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const without_url_context_response = await ai.models.generateContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: [\n",
    "    `\n",
    "        what are the key differences between Gemini 1.5, Gemini 2.0 and Gemini 2.5\n",
    "        models? Create a markdown table comparing the differences.\n",
    "        `,\n",
    "  ],\n",
    "});\n",
    "tslab.display.markdown(without_url_context_response.text ?? \"\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, using the model knowledge only, it does not know about the new Gemini 2.5 models family.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- For more details about using Google Search grounding, check out the [Search Grounding cookbook](Search_Grounding.ipynb).\n",
    "- If you are looking for another scenarios using videos, take a look at the [Video understanding cookbook](Video_understanding.ipynb).\n",
    "\n",
    "Also check the other Gemini capabilities that you can find in the Gemini quickstarts.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
