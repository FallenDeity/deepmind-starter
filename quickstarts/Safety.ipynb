{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini API: Safety Quickstart\n",
    "\n",
    "The Gemini API has adjustable safety settings. This notebook walks you through how to use them. You'll write a prompt that's blocked, see the reason why, and then adjust the filters to unblock it.\n",
    "\n",
    "Safety is an important topic, and you can learn more with the links at the end of this notebook. Here, you will focus on the code\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install the Google GenAI SDK\n",
    "\n",
    "Install the Google GenAI SDK from [npm](https://www.npmjs.com/package/@google/genai). \n",
    "\n",
    "```bash\n",
    "$ npm install @google/genai\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup your API key\n",
    "\n",
    "You can [create](https://aistudio.google.com/app/apikey) your API key using Google AI Studio with a single click.\n",
    "\n",
    "Remember to treat your API key like a password. Don't accidentally save it in a notebook or source file you later commit to GitHub. In this notebook we will be storing the API key in a `.env` file. You can also set it as an environment variable or use a secret manager. \n",
    "\n",
    "Here's how to set it up in a `.env` file:\n",
    "\n",
    "```bash\n",
    "$ touch .env\n",
    "$ echo \"GEMINI_API_KEY=<YOUR_API_KEY>\" >> .env\n",
    "```\n",
    "\n",
    ":::{.callout-tip}\n",
    "\n",
    "Another option is to set the API key as an environment variable. You can do this in your terminal with the following command:\n",
    "\n",
    "```bash\n",
    "$ export GEMINI_API_KEY=\"<YOUR_API_KEY>\"\n",
    "```\n",
    ":::\n",
    "\n",
    "### Load the API key\n",
    "\n",
    "To load the API key from the `.env` file, we will use the `dotenv` package. This package loads environment variables from a `.env` file into `process.env`. \n",
    "\n",
    "```bash\n",
    "$ npm install dotenv\n",
    "```\n",
    "\n",
    "Then, we can load the API key in our code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY is set in the environment variables\n"
     ]
    }
   ],
   "source": [
    "const dotenv = require(\"dotenv\") as typeof import(\"dotenv\");\n",
    "\n",
    "dotenv.config({\n",
    "  path: \"../.env\",\n",
    "});\n",
    "\n",
    "const GEMINI_API_KEY = process.env.GEMINI_API_KEY ?? \"\";\n",
    "if (!GEMINI_API_KEY) {\n",
    "  throw new Error(\"GEMINI_API_KEY is not set in the environment variables\");\n",
    "}\n",
    "console.log(\"GEMINI_API_KEY is set in the environment variables\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "In our particular case the `.env` is is one directory up from the notebook, hence we need to use `../` to go up one directory. If the `.env` file is in the same directory as the notebook, you can omit it altogether. \n",
    "\n",
    "```\n",
    "│\n",
    "├── .env\n",
    "└── quickstarts\n",
    "    └── Safety.ipynb\n",
    "```\n",
    ":::\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize SDK Client\n",
    "\n",
    "With the new SDK, now you only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "const google = require(\"@google/genai\") as typeof import(\"@google/genai\");\n",
    "\n",
    "const ai = new google.GoogleGenAI({ apiKey: GEMINI_API_KEY });\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model\n",
    "\n",
    "Now select the model you want to use in this guide, either by selecting one in the list or writing it down. Keep in mind that some models, like the 2.5 ones are thinking models and thus take slightly more time to respond (cf. [thinking notebook](quickstarts/Get_started_thinking.ipynb) for more details and in particular learn how to switch the thiking off).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "const tslab = require(\"tslab\") as typeof import(\"tslab\");\n",
    "\n",
    "const MODEL_ID = \"gemini-2.5-flash-preview-05-20\";\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send your prompt request to Gemini\n",
    "\n",
    "Pick the prompt you want to use to test the safety filters settings. An examples could be `Write a list of 5 very rude things that I might say to the universe after stubbing my toe in the dark` which was previously tested and trigger the `HARM_CATEGORY_HARASSMENT` and `HARM_CATEGORY_DANGEROUS_CONTENT` categories.\n",
    "\n",
    "The result returned by the `generateContent` method is a [`GenerateContentResponse`](https://googleapis.github.io/js-genai/release_docs/classes/types.GenerateContentResponse.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "const unsafe_response = await ai.models.generateContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: `\n",
    "    I support Martians Soccer Club and I think Jupiterians Football Club\n",
    "    sucks! Write a ironic phrase about them.\n",
    "  `,\n",
    "});\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This response object gives you safety feedback about the candidate answers Gemini generates to you.\n",
    "\n",
    "For each candidate answer you need to check `response.candidates.finishReason`.\n",
    "\n",
    "As you can find on the [Gemini API safety filters documentation](https://ai.google.dev/gemini-api/docs/safety-settings#safety-feedback):\n",
    "\n",
    "- if the `candidate.finishReason` is `FinishReason.STOP` means that your generation request ran successfully\n",
    "- if the `candidate.finishReason` is `FinishReason.SAFETY` means that your generation request was blocked by safety reasons. It also means that the `response.text` structure will be empty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP\n"
     ]
    }
   ],
   "source": [
    "console.log(unsafe_response.candidates?.[0]?.finishReason);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `finishReason` is `FinishReason.SAFETY` you can check which filter caused the block checking the `safetyRatings` list for the candidate answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undefined\n"
     ]
    }
   ],
   "source": [
    "console.log(unsafe_response.candidates?.[0]?.safetyRatings);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are a few ironic phrases about Jupiterians Football Club, playing on the idea that they \"suck\":\n",
       "\n",
       "**Option 1 (Feigned admiration for their unique approach):**\n",
       "\n",
       "> \"Jupiterians Football Club: Consistently expanding our understanding of what 'football' can be... which is often not very much like actual football.\"\n",
       "\n",
       "**Option 2 (Focus on their generosity to opponents):**\n",
       "\n",
       "> \"Jupiterians FC is a shining example of sportsmanship; they're truly dedicated to making the opposing team feel like champions.\"\n",
       "\n",
       "**Option 3 (Understated \"talent\"):**\n",
       "\n",
       "> \"You have to admire Jupiterians Football Club's unwavering commitment to... an extremely long-term rebuilding process.\"\n",
       "\n",
       "**Option 4 (Playing on \"gravity\" for the league table):**\n",
       "\n",
       "> \"Jupiterians FC brings a certain... *gravitational pull* to the bottom of the league table.\"\n",
       "\n",
       "**Option 5 (Complimenting their effort, not results):**\n",
       "\n",
       "> \"Watching Jupiterians Football Club play, you can really see their dedication to *trying*.\"\n",
       "\n",
       "Choose the one that best fits your style!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tslab.display.markdown(unsafe_response.text ?? \"\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing safety settings\n",
    "\n",
    "Depending on the scenario you are working with, it may be necessary to customize the safety filters behaviors to allow a certain degree of unsafety results.\n",
    "\n",
    "To make this customization you must define a `safetySettings` config as part of your `generateContent() `request.\n",
    "\n",
    ":::{.callout-important}\n",
    "\n",
    "To guarantee the Google commitment with the Responsible AI development and its [AI Principles](https://ai.google/responsibility/principles/), for some prompts Gemini will avoid generating the results even if you set all the filters to none.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "const unsafe_response_1 = await ai.models.generateContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: `\n",
    "    I support Martians Soccer Club and I think Jupiterians Football Club\n",
    "    sucks! Write a ironic phrase about them.\n",
    "  `,\n",
    "  config: {\n",
    "    safetySettings: [\n",
    "      {\n",
    "        category: google.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold: google.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "      },\n",
    "      {\n",
    "        category: google.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold: google.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "      },\n",
    "      {\n",
    "        category: google.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold: google.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "      },\n",
    "      {\n",
    "        category: google.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold: google.HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
    "      },\n",
    "    ],\n",
    "  },\n",
    "});\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking again the `candidate.finishReason` information, if the request was not too unsafe, it must show now the value as `FinishReason.STOP` which means that the request was successfully processed by Gemini.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOP\n"
     ]
    }
   ],
   "source": [
    "console.log(unsafe_response_1.candidates?.[0]?.finishReason);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the request was successfully generated, you can check the result on the `response.text`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\"Jupiterians Football Club: They truly excel at making every other team in the league feel like champions.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tslab.display.markdown(unsafe_response_1.text ?? \"\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you check the safety filters ratings, as you set all filters to be ignored, no filtering category was trigerred:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undefined\n"
     ]
    }
   ],
   "source": [
    "console.log(unsafe_response.candidates?.[0]?.safetyRatings);\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning more\n",
    "\n",
    "Learn more with these articles on [safety guidance](https://ai.google.dev/docs/safety_guidance) and [safety settings](https://ai.google.dev/docs/safety_guidance).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Useful API references\n",
    "\n",
    "There are 6 configurable safety settings for the Gemini API:\n",
    "\n",
    "* `HARM_CATEGORY_CIVIC_INTEGRITY`\n",
    "* `HARM_CATEGORY_DANGEROUS_CONTENT`\n",
    "* `HARM_CATEGORY_HARASSMENT`\n",
    "* `HARM_CATEGORY_SEXUALLY_EXPLICIT`\n",
    "* `HARM_CATEGORY_HATE_SPEECH`\n",
    "* `HARM_CATEGORY_UNSPECIFIED`\n",
    "\n",
    "You can refer to the safety settings using either their full name, or the aliases like `DANGEROUS`.\n",
    "\n",
    "- They can also be passed on each request to [generateContent](https://googleapis.github.io/js-genai/release_docs/classes/models.Models.html#generatecontent) or [ChatSession.send_message](https://googleapis.github.io/js-genai/release_docs/classes/chats.Chat.html#sendmessage).\n",
    "- The [GenerateContentResponse](https://googleapis.github.io/js-genai/release_docs/classes/types.GenerateContentResponse.html) returns [SafetyRatings](https://googleapis.github.io/js-genai/release_docs/interfaces/types.SafetyRating.html) for the prompt in the [GenerateContentResponse.promptFeedback](https://googleapis.github.io/js-genai/release_docs/classes/types.GenerateContentResponsePromptFeedback.html), and for each [Candidate](https://googleapis.github.io/js-genai/release_docs/interfaces/types.Candidate.html) in the `safetyRatings` attribute.\n",
    "- A [SafetySetting](https://googleapis.github.io/js-genai/release_docs/interfaces/types.SafetySetting.html) contains:\n",
    "  - [HarmCategory](https://googleapis.github.io/js-genai/release_docs/enums/types.HarmCategory.html)\n",
    "  - [HarmBlockThreshold](https://googleapis.github.io/js-genai/release_docs/enums/types.HarmBlockThreshold.html)\n",
    "- A [SafetyRating](https://googleapis.github.io/js-genai/release_docs/interfaces/types.SafetyRating.html) contains:\n",
    "  - [HarmCategory](https://googleapis.github.io/js-genai/release_docs/enums/types.HarmCategory.html)\n",
    "  - [HarmProbability](https://googleapis.github.io/js-genai/release_docs/enums/types.HarmProbability.html)\n",
    "\n",
    "The [HarmCategory](https://googleapis.github.io/js-genai/release_docs/enums/types.HarmCategory.html) enum includes both the categories for PaLM and Gemini models.\n",
    "\n",
    "- When specifying enum values the SDK will accept the enum values themselves, or their integer or string representations.\n",
    "- The SDK will also accept abbreviated string representations: `[\"HARM_CATEGORY_DANGEROUS_CONTENT\", \"DANGEROUS_CONTENT\", \"DANGEROUS\"]` are all valid. Strings are case insensitive.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
